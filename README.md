# Graduate-Admission-Prediction
This project predicts the chances of a student's admission to a graduate school based on various academic factors. An Artificial Neural Network (ANN) is built using TensorFlow and Keras to perform this prediction.

üìã The Dataset
The analysis is based on the "Graduate Admissions" dataset, which comprises data for 500 applicants. Each record includes the following parameters:

‚Ä¢ GRE Score: (Max 340) - The Graduate Record Examination is a standardized test that is an admissions requirement for many graduate schools. It measures verbal reasoning, quantitative reasoning, analytical writing, and critical thinking skills.

‚Ä¢ TOEFL Score: (Max 120) - The Test of English as a Foreign Language is a standardized test to measure the English language ability of non-native speakers wishing to enroll in English-speaking universities.

‚Ä¢ University Rating: (Scale 1-5) - A rating of the applicant's undergraduate university. A higher rating generally indicates a more prestigious and rigorous academic background.

‚Ä¢ SOP (Statement of Purpose): (Scale 1-5) - An assessment of the applicant's statement of purpose, a crucial essay where they articulate their goals, motivations, and suitability for the program.

‚Ä¢ LOR (Letter of Recommendation): (Scale 1-5) - A score representing the strength and quality of the letters of recommendation submitted on behalf of the applicant.

‚Ä¢ CGPA (Cumulative Grade Point Average): (Max 10) - The applicant's undergraduate GPA, a primary indicator of academic performance.

‚Ä¢ Research Experience: (Binary: 0 or 1) - Indicates whether the applicant has prior research experience (1 for Yes, 0 for No). This is often a critical factor for research-focused graduate programs.

‚Ä¢ Chance of Admit: (Range 0-1) - The target variable. This is the probability of a student being admitted, which the model aims to predict.

‚öôÔ∏è Project Workflow
The project follows a systematic machine learning pipeline:

1. Data Loading and Preprocessing:

--> The dataset is loaded into a pandas DataFrame.

--> The 'Serial No.' column is removed as it serves only as an index and has no predictive value.

--> A preliminary check is performed to ensure there are no missing values or duplicate entries that could skew the model's performance.

--> The dataset is then partitioned into features (independent variables, X) and the target (dependent variable, y).

2. Data Splitting and Scaling:

The data is divided into training (80%) and testing (20%) sets. This separation ensures that the model can be evaluated on unseen data.

--> Feature Scaling: The features are normalized using MinMaxScaler. This scales all numerical features to a range between 0 and 1. Scaling is crucial for neural networks as it helps the gradient descent algorithm converge faster and more effectively.

3. Model Building (ANN Architecture):

A sequential ANN model is defined using the Keras API.

--> Input Layer: Contains 7 neurons, one for each input feature. The ReLU (Rectified Linear Unit) activation function is used to introduce non-linearity, allowing the model to learn more complex patterns.

--> Hidden Layer: Also contains 7 neurons with ReLU activation. This layer processes the information from the input layer to learn higher-level representations.

--> Output Layer: Consists of a single neuron. A linear activation function is used because this is a regression problem where the goal is to predict a continuous value (the probability of admission).

4. Model Compilation and Training:

‚Ä¢ Compilation: The model is configured for training using the compile method.

--> Optimizer: The Adam optimizer is chosen. It is an efficient and widely used optimization algorithm that adjusts the learning rate during training.

--> Loss Function: Mean Squared Error (MSE) is used as the loss function, which is standard for regression tasks. It measures the average of the squares of the errors between the predicted and actual values.

‚Ä¢ Training: The model is trained using the fit method on the scaled training data for 100 epochs. An epoch is one complete pass through the entire training dataset. A validation split of 20% of the training data is used to monitor the model's performance on a separate validation set during training, helping to detect overfitting.

5. Model Evaluation:

--> The trained model's predictive power is assessed on the unseen test data.

--> The R-squared (R¬≤) metric is used for evaluation. R¬≤ represents the proportion of the variance in the dependent variable that is predictable from the independent variables. An R¬≤ score of 0.80 indicates that the model can explain approximately 80% of the variability in the admission chances, which signifies a reasonably good fit.

--> A plot of the training and validation loss over the epochs is generated to visualize how the model's error rate decreased during training.

üõ†Ô∏è Technologies and Libraries Used
‚Ä¢ Python 3

‚Ä¢ NumPy: For efficient numerical computations.

‚Ä¢ Pandas: For data loading, cleaning, and manipulation.

‚Ä¢ Scikit-learn: For splitting the data, scaling features, and model evaluation.

‚Ä¢ TensorFlow & Keras: For building, training, and evaluating the deep learning model.

‚Ä¢ Matplotlib: For creating visualizations, such as the loss curve.

üöÄ How to Run the Project
1.Clone the Repository:

git clone <repository-url>
cd <repository-directory>

2. Set up a Virtual Environment (Recommended):

python -m venv env
source env/bin/activate  # On Windows, use `env\Scripts\activate`

3. Install Dependencies: Ensure you have Python and the required libraries installed.

pip install numpy pandas scikit-learn tensorflow matplotlib

4. Download the Dataset: Obtain the Admission_Predict_Ver1.1.csv file and place it in the project's root directory.

5.Run the Notebook: Launch Jupyter Notebook and open the .ipynb file to execute the code cells sequentially.

jupyter notebook


